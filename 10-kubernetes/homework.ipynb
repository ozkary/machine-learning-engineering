{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Kubernetes\n",
    "\n",
    "In this homework, we'll deploy the credit scoring model from the homework 5. We already have a docker image for this model - we'll use it for deploying the model to Kubernetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download all the files at this folder_url and write them to the folder ./src\n",
    "\n",
    "folder_url = 'https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2023/05-deployment/homework'\n",
    "raw_url = 'https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2023/05-deployment/homework/'\n",
    "\n",
    "# get every file in the folder\n",
    "response = requests.get(folder_url)\n",
    "\n",
    "# convert the response text to JSON dictionary\n",
    "folder_json = response.json()\n",
    "print(folder_json.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the keys in the payload node\n",
    "# print(folder_json['payload']['tree']['items'])\n",
    "\n",
    "# for each item, download the file and write it to the folder ./src\n",
    "for item in folder_json['payload']['tree']['items']:\n",
    "    print(item['path'])\n",
    "    file_name = item['path'].split('/')[-1]\n",
    "    \n",
    "    # get the github raw url for the folder url in order to download the file        \n",
    "    file_url = raw_url + '/' + file_name\n",
    "    print(file_url)\n",
    "    file_response = requests.get(file_url)\n",
    "    # write the file to the folder ./src with bytes\n",
    "    with open('./src/' + file_name, 'wb') as f:\n",
    "        f.write(file_response.content)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Docker image\n",
    "- With a terminal, open the src folder. There should be a Dockerfile\n",
    "  \n",
    "```bash\n",
    "docker build -t zoomcamp-model:hw10 .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - What is the credit score\n",
    "\n",
    "- Run it to test that it's working locally:\n",
    "\n",
    "```bash \n",
    "docker run -it --rm -p 9696:9696 zoomcamp-model:hw10\n",
    "```\n",
    "- And in another terminal, execute q6_test.py file:\n",
    "```bash\n",
    "python3 q6_test.py\n",
    "```\n",
    "You should see this:\n",
    "\n",
    "```bash\n",
    "{'get_credit': True, 'get_credit_probability': <value>}\n",
    "```\n",
    "Here <value> is the probability of getting a credit card. You need to choose the right one.\n",
    "\n",
    "- 0.3269\n",
    "- 0.5269\n",
    "- 0.7269 *\n",
    "- 0.9269\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'get_credit': True, 'get_credit_probability': 0.726936946355423}\n"
     ]
    }
   ],
   "source": [
    "# run the test file to get the result\n",
    "!python3 ./src/q6_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop the Docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                 COMMAND                  CREATED          STATUS          PORTS                    NAMES\n",
      "ecd7a30f90c4   zoomcamp-model:hw10   \"waitress-serve --liâ€¦\"   39 seconds ago   Up 37 seconds   0.0.0.0:9696->9696/tcp   wizardly_bose\n",
      "ecd7a30f90c4\n"
     ]
    }
   ],
   "source": [
    "# check the running containers\n",
    "!docker ps\n",
    "\n",
    "!docker stop ecd7a30f90c4   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install kubectl\n",
    "\n",
    "```bash\n",
    "# check the processor name amd or arm\n",
    "uname -m\n",
    "\n",
    "# Download the latest version of kubectl\n",
    "sudo curl -Lo /usr/local/bin/kubectl https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl\n",
    "\n",
    "# Make kubectl executable\n",
    "sudo chmod +x /usr/local/bin/kubectl\n",
    "\n",
    "# Verify installation\n",
    "kubectl version --client\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install kind\n",
    "\n",
    "```bash\n",
    "# Download kind\n",
    "sudo curl -Lo /usr/local/bin/kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64\n",
    "\n",
    "# Make kind executable\n",
    "sudo chmod +x /usr/local/bin/kind\n",
    "\n",
    "# Verify installation\n",
    "kind version\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"clientVersion\": {\n",
      "    \"major\": \"1\",\n",
      "    \"minor\": \"25\",\n",
      "    \"gitVersion\": \"v1.25.4\",\n",
      "    \"gitCommit\": \"872a965c6c6526caa949f0c6ac028ef7aff3fb78\",\n",
      "    \"gitTreeState\": \"clean\",\n",
      "    \"buildDate\": \"2022-11-09T13:36:36Z\",\n",
      "    \"goVersion\": \"go1.19.3\",\n",
      "    \"compiler\": \"gc\",\n",
      "    \"platform\": \"linux/amd64\"\n",
      "  },\n",
      "  \"kustomizeVersion\": \"v4.5.7\"\n",
      "}\n",
      "The connection to the server localhost:8080 was refused - did you specify the right host or port?\n",
      "kind v0.20.0 go1.20.4 linux/amd64\n"
     ]
    }
   ],
   "source": [
    "!kubectl version --output=json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - What is the version of kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind v0.20.0 go1.20.4 linux/amd64\n"
     ]
    }
   ],
   "source": [
    "!kind version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a cluster\n",
    "\n",
    "- Now let's create a cluster with kind:\n",
    "\n",
    "```bash\n",
    "kind create cluster\n",
    "\n",
    "```\n",
    "- And check with kubectl that it was successfully created:\n",
    "\n",
    "```bash\n",
    "kubectl cluster-info\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - What's CLUSTER-IP of the service that is already running there?\n",
    "\n",
    "Use kubectl to get the list of running services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\n",
      "kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   84m\n"
     ]
    }
   ],
   "source": [
    "!kubectl get services\n",
    "# import requests\n",
    "\n",
    "# response = requests.get('https://127.0.0.1:36891/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy')\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 \n",
    "\n",
    "To be able to use the docker image we previously created (zoomcamp-model:hw10), we need to register it with kind.\n",
    "\n",
    "What's the command we need to run for that?\n",
    "\n",
    "- kind create cluster\n",
    "- kind build node-image\n",
    "- kind load docker-image *\n",
    "- kubectl apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: \"zoomcamp-model:hw10\" with ID \"sha256:aa9f3a58297d139f06e678b54779c12db09f29c2733ed44ccfb5757cb4ab7a4c\" not yet present on node \"kind-control-plane\", loading...\n"
     ]
    }
   ],
   "source": [
    "!kind load docker-image zoomcamp-model:hw10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 - \n",
    "\n",
    "Now let's create a deployment config (e.g. deployment.yaml)\n",
    "\n",
    "```python\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: credit\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: credit\n",
    "  replicas: 1\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: credit\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: credit\n",
    "        image: <Image>\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"64Mi\"\n",
    "            cpu: \"100m\"            \n",
    "          limits:\n",
    "            memory: <Memory>\n",
    "            cpu: <CPU>\n",
    "        ports:\n",
    "        - containerPort: <Port>\n",
    "```\n",
    "\n",
    "Replace <Image>, <Memory>, <CPU>, <Port> with the correct values.\n",
    "\n",
    "What is the value for <Port>? **9696**\n",
    "\n",
    "Apply this deployment using the appropriate command and get a list of running Pods. You can see one running Pod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/credit created\n"
     ]
    }
   ],
   "source": [
    " !kubectl apply -f ./src/deployment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME     READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "credit   1/1     1            1           6m20s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 -  What do we need to write instead of <???>?\n",
    "\n",
    "Let's create a service for this deployment (service.yaml):\n",
    "\n",
    "```python\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: <Service name>\n",
    "spec:\n",
    "  type: LoadBalancer\n",
    "  selector:\n",
    "    app: <???>\n",
    "  ports:\n",
    "  - port: 80\n",
    "    targetPort: <PORT>\n",
    "```\n",
    "\n",
    "Use the deployment name from the `!kubectl get deployments` output  and apply the file as:\n",
    "\n",
    "```bash\n",
    "kubectl apply -f ./src/service.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/ozkary-credit-service created\n"
     ]
    }
   ],
   "source": [
    "# apply the service.yaml file\n",
    "!kubectl apply -f ./src/service.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the service\n",
    "\n",
    "We can test our service locally by forwarding the port 9696 on our computer to the port 80 on the service:\n",
    "\n",
    "kubectl port-forward service/<Service name> 9696:80\n",
    "Run q6_test.py (from the homework 5) once again to verify that everything is working. You should get the same result as in Question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarding from 127.0.0.1:9696 -> 9696\n",
      "Forwarding from [::1]:9696 -> 9696\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!kubectl port-forward service/ozkary-credit-service 9696:80 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'get_credit': True, 'get_credit_probability': 0.726936946355423}\n"
     ]
    }
   ],
   "source": [
    "!python3 ./src/q6_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoscaling\n",
    "\n",
    "Now we're going to use a HorizontalPodAutoscaler (HPA for short) that automatically updates a workload resource (such as our deployment), with the aim of automatically scaling the workload to match demand.\n",
    "\n",
    "Use the following command to create the HPA:\n",
    "\n",
    "```bash\n",
    "kubectl autoscale deployment credit --name credit-hpa --cpu-percent=20 --min=1 --max=3\n",
    "```\n",
    "You can check the current status of the new HPA by running:\n",
    "\n",
    "```bash\n",
    "kubectl get hpa\n",
    "```\n",
    "\n",
    "The output should be similar to the next:\n",
    "```bash\n",
    "NAME              REFERENCE                TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\n",
    "credit-hpa   Deployment/credit   1%/20%    1         3         1          27s\n",
    "\n",
    "```\n",
    "\n",
    "TARGET column shows the average CPU consumption across all the Pods controlled by the corresponding deployment. Current CPU consumption is about 0% as there are no clients sending requests to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         REFERENCE           TARGETS         MINPODS   MAXPODS   REPLICAS   AGE\n",
      "credit-hpa   Deployment/credit   <unknown>/20%   1         3         1          8m32s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get hpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase the load\n",
    "\n",
    "Let's see how the autoscaler reacts to increasing the load. To do this, we can slightly modify the existing q6_test.py script by putting the operator that sends the request to the credit service into a loop.\n",
    "\n",
    "```bash\n",
    "while True:\n",
    "    sleep(0.1)\n",
    "    response = requests.post(url, json=client).json()\n",
    "    print(response)\n",
    "```\n",
    "\n",
    "Now you can run this script.**Use q6_test_loop.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 - What was the maximum amount of the replicas during this test?\n",
    "\n",
    "Run kubectl get hpa credit-hpa --watch command to monitor how the autoscaler performs. Within a minute or so, you should see the higher CPU load; and then - more replicas. What was the maximum amount of the replicas during this test?\n",
    "\n",
    "- 1\n",
    "- 2\n",
    "- 3\n",
    "- 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         REFERENCE           TARGETS         MINPODS   MAXPODS   REPLICAS   AGE\n",
      "credit-hpa   Deployment/credit   <unknown>/20%   1         3         1          19m\n"
     ]
    }
   ],
   "source": [
    "!kubectl get hpa credit-hpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop all the services\n",
    "\n",
    "```bash\n",
    "kubectl delete service,deployment ozkary-credit-service credit\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service \"ozkary-credit-service\" deleted\n",
      "deployment.apps \"credit\" deleted\n",
      "Error from server (NotFound): services \"credit\" not found\n",
      "Error from server (NotFound): deployments.apps \"ozkary-credit-service\" not found\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete service,deployment ozkary-credit-service credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service \"kubernetes\" deleted\n",
      "horizontalpodautoscaler.autoscaling \"credit-hpa\" deleted\n"
     ]
    }
   ],
   "source": [
    "# delete all the resources\n",
    "!kubectl delete all --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting cluster \"kind\" ...\n",
      "Deleted nodes: [\"kind-control-plane\"]\n"
     ]
    }
   ],
   "source": [
    "# delete the cluster\n",
    "!kind delete cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kill the port forwarding process\n",
    "!pkill -f 'kubectl port-forward'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
