{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug to Drug Interaction - Predicting the interaction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the XGBoost model for our predictions.\n",
    "\n",
    "- Load the ./data/test_cases.csv file\n",
    "  - Process the features and create the ssp value  \n",
    "- Load the model  \n",
    "  - Load the ./models/hd_xgboost_model.pkl.bin\n",
    "  - Load the ./models/hd_dictvectorizer.pkl.bin\n",
    "- Call Predict  \n",
    "  - Display the interaction type statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import pickle\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDIModelLoader():\n",
    "    \"\"\" \n",
    "    Class to load a model from a pickle file and make predictions\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path, encoder_path=None):\n",
    "        self.model_path = model_path\n",
    "        self.encoder_path = encoder_path\n",
    "        self.model = None\n",
    "        self.encoder = None\n",
    "        self.load_model()\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\" \n",
    "        Load the model from the pickle file\n",
    "        Load encoder if use_encoder is set\n",
    "        \"\"\"\n",
    "\n",
    "        with open(self.model_path, 'rb') as model:\n",
    "            self.model = pickle.load(model)\n",
    "\n",
    "        if self.encoder_path is not None:\n",
    "            with open(self.encoder_path, 'rb') as encoder:\n",
    "                self.encoder = pickle.load(encoder)        \n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # Transform the data\n",
    "        # X_encoded = self.encoder.transform(X)\n",
    "        \n",
    "        # Predict the results\n",
    "        y_pred = self.model.predict(X)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDIPredictor:\n",
    "    \"\"\"\n",
    "    Maps the predictions to the original labels and meaning\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path, encoder_path, data_path):\n",
    "        self.model = DDIModelLoader(model_path, encoder_path)\n",
    "        self.interactions = None\n",
    "        self.data_path = data_path        \n",
    "        self.drug_pca_lookup = None\n",
    "        self.load_drug_pca_lookup()\n",
    "\n",
    "    def load_drug_pca_lookup(self):\n",
    "        \"\"\" \n",
    "        Load the drug pca lookup from pickle file\n",
    "        \"\"\"\n",
    "        if self.drug_pca_lookup is None:\n",
    "            pca_drugs = pd.read_csv(f'{self.data_path}drugbank_pca50.csv.gz', index_col=0)            \n",
    "            pca_drugs['name'] = pca_drugs['name'].str.lower()\n",
    "            # convert drugs to a dictionary using name in lowercase as the key\n",
    "            self.drug_pca_lookup = pca_drugs.set_index('name').T.to_dict('list')\n",
    "            \n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\" \n",
    "        Predict the results and map them to the original labels\n",
    "        \"\"\"       \n",
    "        return self.model.predict(X)    \n",
    "    \n",
    "    def feature_names(self):\n",
    "        \"\"\" \n",
    "        Return the feature names\n",
    "        \"\"\"\n",
    "        # if the property feature name exists, return it\n",
    "        if hasattr(self.model.model, 'feature_names'):\n",
    "            return self.model.feature_names\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def build_model_input(self, rxs, features=101):\n",
    "        \"\"\" \n",
    "        Build the message to be returned using a pca lookup\n",
    "        \"\"\"        \n",
    "        # select the mean of the pc_ columns from the dict_drugs\n",
    "        mean_pca = np.mean(list(self.drug_pca_lookup.values()), axis=0).tolist()\n",
    "\n",
    "        #for each unique drug name in rxs do a lookup to get the pca values\n",
    "        inputs = []\n",
    "        for rx in rxs:\n",
    "            # from the dict get all the keys with the drug names\n",
    "            pca_drug = []            \n",
    "            for label in ['drug1','drug2']:    \n",
    "                name = rx[label].lower()                                \n",
    "                pca = self.drug_pca_lookup[name] if name in self.drug_pca_lookup else mean_pca       \n",
    "                pca_drug = pca_drug + pca\n",
    "            pca_drug = pca_drug + [rx['ssp']]            \n",
    "            inputs = inputs + [pca_drug]\n",
    "      \n",
    "        # convert the list to a numpy array to see the shape\n",
    "        X = np.array(inputs)\n",
    "        print(X.shape)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def build_model_message(self, ssp_values, features=101):\n",
    "        \"\"\" \n",
    "        Build the message to be returned\n",
    "        \"\"\"        \n",
    "        X = np.zeros((len(ssp_values), features))                \n",
    "        for index, ssp in enumerate(ssp_values):                \n",
    "            X[index,-1] = ssp\n",
    "\n",
    "        print(X.shape)        \n",
    "        return X\n",
    "\n",
    "    def get_ddi_description(self, results):\n",
    "        # check if the list is empty\n",
    "\n",
    "        if len(results) == 0:\n",
    "            return None\n",
    "        \n",
    "        if self.interactions is None:\n",
    "            self.load_interactions()\n",
    "\n",
    "        notes = []\n",
    "        for result in results:\n",
    "            # select the row with ddi_type = result\n",
    "            ddi_type = int(result['result']) + 1\n",
    "            ddi_row = self.interactions.loc[self.interactions['ddi_type'] == ddi_type]            \n",
    "            # add one to the result to match the encoding during training            \n",
    "            note = f'No interaction found for {result[\"drug1\"]} and {result[\"drug2\"]}'\n",
    "            if ddi_row is not None and len(ddi_row) > 0:\n",
    "                note = ddi_row['description'].to_string(index=False).replace('#Drug1', result['drug1']).replace('#Drug2', result['drug2'])\n",
    "            \n",
    "            notes.append(note)\n",
    "            \n",
    "        return notes\n",
    "        \n",
    "    def load_interactions(self):\n",
    "        \"\"\" \n",
    "        Load the interactions from csv        \n",
    "        \"\"\"\n",
    "        df = pd.read_csv(f'{self.data_path}interaction_types.csv')\n",
    "\n",
    "        #rename the columns to lowercase and replace spaces with underscore\n",
    "        df.columns = map(str.lower, df.columns)\n",
    "        df.columns = df.columns.str.replace(' ', '_')\n",
    "\n",
    "        # remove the DDI type text from the ddi_type column\n",
    "        df['ddi_type'] = df['ddi_type'].str.replace('DDI type ', '')\n",
    "\n",
    "        # cast the ddi_type column to integer\n",
    "        df['ddi_type'] = df['ddi_type'].astype(int)\n",
    "        self.interactions = df\n",
    "\n",
    "    def calculate_ssp(self, smiles_drug1, smiles_drug2):\n",
    "\n",
    "        \"\"\" \n",
    "        Structural Similarity Profile (SSP) for drug pairs  \n",
    "        \"\"\"\n",
    "\n",
    "        # check if the SMILE code is valid\n",
    "        if smiles_drug1 is None or smiles_drug2 is None:\n",
    "            return 0\n",
    "        \n",
    "        try:\n",
    "            mol_drug1 = Chem.MolFromSmiles(smiles_drug1)\n",
    "            mol_drug2 = Chem.MolFromSmiles(smiles_drug2)\n",
    "\n",
    "            fp_drug1 = AllChem.GetMorganFingerprintAsBitVect(mol_drug1, 2, nBits=1024)\n",
    "            fp_drug2 = AllChem.GetMorganFingerprintAsBitVect(mol_drug2, 2, nBits=1024)\n",
    "\n",
    "            array_fp_drug1 = np.array(list(fp_drug1.ToBitString())).astype(int)\n",
    "            array_fp_drug2 = np.array(list(fp_drug2.ToBitString())).astype(int)\n",
    "\n",
    "            tanimoto_similarity = np.sum(np.logical_and(array_fp_drug1, array_fp_drug2)) / np.sum(np.logical_or(array_fp_drug1, array_fp_drug2))\n",
    "\n",
    "            return tanimoto_similarity\n",
    "        except:\n",
    "            return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_cases():\n",
    "    \"\"\" \n",
    "    Load the test cases from the csv file\n",
    "    \"\"\"\n",
    "    df_test_cases = pd.read_csv('./data/test_cases.csv')\n",
    "    # make all columns lowercase and replace spaces with underscores\n",
    "    df_test_cases.columns = [col.lower().replace(' ', '_') for col in df_test_cases.columns]\n",
    "\n",
    "    # convert the data into a drug pair using the prescription column\n",
    "    prescriptions = {}\n",
    "    for index, row in df_test_cases.iterrows():\n",
    "        rx = row['prescription']\n",
    "        if rx not in prescriptions:        \n",
    "            prescriptions[rx] = {}\n",
    "        \n",
    "        # get the key count to start bulding the properties\n",
    "        key_count = 1 if len(prescriptions[rx]) == 0 else 2\n",
    "        drug = f'drug{key_count}'\n",
    "        smile = f'smiles{key_count}'        \n",
    "        prescriptions[rx][drug] = row['drug_name'] \n",
    "        prescriptions[rx][smile] = row['smiles'] \n",
    "   \n",
    "    return prescriptions    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, path='./'):\n",
    "    \"\"\" \n",
    "    Predict the DDI for the given data\n",
    "    \"\"\"        \n",
    "\n",
    "     # load the model\n",
    "    data_path = os.path.join(path,'data/')\n",
    "    model_path = os.path.join(path,'models')\n",
    "    print('resources',model_path, data_path)\n",
    "\n",
    "    model_file = f'{model_path}/ozkary_ddi_xgboost.pkl.bin'\n",
    "    encoder_file = F'{model_path}/ozkary_ddi_encoder.pkl.bin'\n",
    "\n",
    "    predictor = DDIPredictor(model_file, encoder_file, data_path)\n",
    "\n",
    "    prescriptions = data\n",
    "\n",
    "    if not isinstance(prescriptions, dict):\n",
    "        raise Exception(f'Invalid data type. Expected a dictionary {data}')\n",
    "\n",
    "    # for each drug pair calculate the structural similarity profile\n",
    "    for rx in prescriptions:        \n",
    "        drug1 = prescriptions[rx]['smiles1']\n",
    "        drug2 = prescriptions[rx]['smiles2']\n",
    "        prescriptions[rx]['ssp'] = predictor.calculate_ssp(drug1, drug2)\n",
    "        \n",
    "    print(prescriptions.values())\n",
    "\n",
    "    # select all the ssp values from the list\n",
    "    ssp_values = [item['ssp'] for item in prescriptions.values()]\n",
    "    # X = predictor.build_model_message(ssp_values)\n",
    "    X = predictor.build_model_input(prescriptions.values())\n",
    "    \n",
    "    # run a prediction\n",
    "    y_pred = predictor.predict(X)\n",
    "    print('Predictions ', y_pred)\n",
    "    # for each y_pred value add it to the dictionary    \n",
    "    for index, item in enumerate(prescriptions.values()):\n",
    "        item['result'] = y_pred[index]        \n",
    "    \n",
    "    # print the results\n",
    "    print('Results ',prescriptions.values())\n",
    "\n",
    "    # load the interactions types file\n",
    "    result = predictor.get_ddi_description(prescriptions.values())\n",
    "    \n",
    "    print('Description ', result)\n",
    "    return result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resources ./models ./data/\n",
      "dict_values([{'drug1': 'Ritonavir', 'smiles1': 'CC(C)[C@H](NC(=O)N(C)CC1=CSC(=N1)C(C)C)C(=O)N[C@H](C[C@H](O)[C@H](CC1=CC=CC=C1)NC(=O)OCC1=CN=CS1)CC1=CC=CC=C1', 'drug2': 'Formoterol', 'smiles2': 'COC1=CC=C(CC(C)NCC(O)C2=CC(NC=O)=C(O)C=C2)C=C1', 'ssp': 0.1941747572815534}, {'drug1': 'Ritonavir', 'smiles1': 'CC(C)[C@H](NC(=O)N(C)CC1=CSC(=N1)C(C)C)C(=O)N[C@H](C[C@H](O)[C@H](CC1=CC=CC=C1)NC(=O)OCC1=CN=CS1)CC1=CC=CC=C1', 'drug2': 'Olodaterol', 'smiles2': 'COC1=CC=C(CC(C)(C)NC[C@H](O)C2=C3OCC(=O)NC3=CC(O)=C2)C=C1', 'ssp': 0.1592920353982301}, {'drug1': 'Phentermine', 'smiles1': 'CC(C)(N)CC1=CC=CC=C1', 'drug2': 'Brexpiprazole', 'smiles2': 'O=C1NC2=CC(OCCCCN3CCN(CC3)C3=C4C=CSC4=CC=C3)=CC=C2C=C1', 'ssp': 0.08823529411764706}, {'drug1': 'Mirtazapine', 'smiles1': 'CN1CCN2C(C1)C1=CC=CC=C1CC1=C2N=CC=C1', 'drug2': 'Phenylephrine', 'smiles2': 'CNC[C@H](O)C1=CC(O)=CC=C1', 'ssp': 0.0847457627118644}])\n",
      "(4, 101)\n",
      "Predictions  [46 48 74 46]\n",
      "Results  dict_values([{'drug1': 'Ritonavir', 'smiles1': 'CC(C)[C@H](NC(=O)N(C)CC1=CSC(=N1)C(C)C)C(=O)N[C@H](C[C@H](O)[C@H](CC1=CC=CC=C1)NC(=O)OCC1=CN=CS1)CC1=CC=CC=C1', 'drug2': 'Formoterol', 'smiles2': 'COC1=CC=C(CC(C)NCC(O)C2=CC(NC=O)=C(O)C=C2)C=C1', 'ssp': 0.1941747572815534, 'result': 46}, {'drug1': 'Ritonavir', 'smiles1': 'CC(C)[C@H](NC(=O)N(C)CC1=CSC(=N1)C(C)C)C(=O)N[C@H](C[C@H](O)[C@H](CC1=CC=CC=C1)NC(=O)OCC1=CN=CS1)CC1=CC=CC=C1', 'drug2': 'Olodaterol', 'smiles2': 'COC1=CC=C(CC(C)(C)NC[C@H](O)C2=C3OCC(=O)NC3=CC(O)=C2)C=C1', 'ssp': 0.1592920353982301, 'result': 48}, {'drug1': 'Phentermine', 'smiles1': 'CC(C)(N)CC1=CC=CC=C1', 'drug2': 'Brexpiprazole', 'smiles2': 'O=C1NC2=CC(OCCCCN3CCN(CC3)C3=C4C=CSC4=CC=C3)=CC=C2C=C1', 'ssp': 0.08823529411764706, 'result': 74}, {'drug1': 'Mirtazapine', 'smiles1': 'CN1CCN2C(C1)C1=CC=CC=C1CC1=C2N=CC=C1', 'drug2': 'Phenylephrine', 'smiles2': 'CNC[C@H](O)C1=CC(O)=CC=C1', 'ssp': 0.0847457627118644, 'result': 46}])\n",
      "Description  ['Ritonavir may increase the antihypertensive activi...', 'Ritonavir may increase the antipsychotic activitie...', 'Phentermine may increase the photosensitizing activi...', 'Mirtazapine may increase the antihypertensive activi...']\n",
      "Ritonavir may increase the antihypertensive activi...\n",
      "Ritonavir may increase the antipsychotic activitie...\n",
      "Phentermine may increase the photosensitizing activi...\n",
      "Mirtazapine may increase the antihypertensive activi...\n"
     ]
    }
   ],
   "source": [
    "# add a main function for the entry point to the program\n",
    "# if __name__ == '__main__':\n",
    "#     os.system('clear')\n",
    "#     print('Running DDI main function')\n",
    "\n",
    "prescriptions = load_test_cases()\n",
    "results = predict(prescriptions)\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/jupyter:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import load_entry_point\n",
      "[NbConvertApp] Converting notebook data_predict.ipynb to script\n",
      "[NbConvertApp] Writing 7422 bytes to data_predict.py\n"
     ]
    }
   ],
   "source": [
    "# save the notebook to code\n",
    "!jupyter nbconvert --to script data_predict.ipynb\n",
    "\n",
    "# move to the ddi_lib folder\n",
    "!mv data_predict.py ./ddi_lib/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
