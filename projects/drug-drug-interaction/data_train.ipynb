{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug to Drug Interaction (DDI) - Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the ./data/ssp_interaction_type.csv.gz\n",
    "- Process the features\n",
    "  - Set the categorical features names\n",
    "  - Set the numeric features names  \n",
    "  - Set the target variable\n",
    "- Split the data\n",
    "  - train/validation/test split with 60%/20%/20% distribution.\n",
    "  - Random_state 42\n",
    "  - Use strategy = y to deal with the class imbalanced problem\n",
    "- Train the model\n",
    "  - LogisticRegression\n",
    "  - RandomForestClassifier\n",
    "  - XGBClassifier\n",
    "  - DecisionTreeClassifier\n",
    "- Evaluate the models and compare them\n",
    "  - accuracy_score\n",
    "  - precision_score\n",
    "  - recall_score\n",
    "  - f1_score\n",
    "- Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 191808 entries, 0 to 191807\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   ssp               191808 non-null  float64\n",
      " 1   interaction_type  191808 non-null  int64  \n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 2.9 MB\n",
      "None\n",
      "        ssp  interaction_type\n",
      "0  0.091837                 1\n",
      "1  0.093023                 1\n",
      "2  0.012346                 1\n",
      "3  0.069307                 1\n",
      "4  0.043103                 1\n"
     ]
    }
   ],
   "source": [
    "# open the csv file and read it into a pandas dataframe \n",
    "df = pd.read_csv('./data/ssp_interaction_type.csv.gz', compression='gzip')\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class DDITrainData():\n",
    "    \"\"\"\n",
    "    Class to hold the training data for the DDI project\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, target_variable='interaction_type'):\n",
    "        self.df = df\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.target_variable = target_variable\n",
    "        self.categorical_features = None\n",
    "        self.numerical_features = None\n",
    "        # list of all features\n",
    "        self.all_features = None\n",
    "        \n",
    "    def process_features(self):\n",
    "        \"\"\"\n",
    "        Process the features for the model\n",
    "        \"\"\"        \n",
    "        # get the features\n",
    "        self.categorical_features = list(self.df.select_dtypes(include=['object']).columns)\n",
    "        self.numerical_features = list(self.df.select_dtypes(include=[np.number]).columns)\n",
    "\n",
    "        # remove the target feature from the list of numeric features\n",
    "        if self.target_variable in self.numerical_features:\n",
    "            self.numerical_features.remove(self.target_variable)\n",
    "\n",
    "        print('Categorical features',self.categorical_features)\n",
    "        print('Numerical features',self.numerical_features)\n",
    "        print('Target feature',self.target_variable)\n",
    "\n",
    "        # create a list of all features\n",
    "        self.all_features = self.categorical_features + self.numerical_features\n",
    "                \n",
    "        return self.categorical_features, self.numerical_features\n",
    "    \n",
    "    def split_data(self, test_size=0.2, random_state=42):\n",
    "        \"\"\"\n",
    "        Split the data into training and validation sets\n",
    "        \"\"\"\n",
    "        # split the data in train/val/test sets, with 60%/20%/20% distribution with seed 1\n",
    "        X = self.df[self.all_features]\n",
    "        y = self.df[self.target_variable]\n",
    "        X_full_train, X_test, y_full_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "\n",
    "        # .25 splits the 80% train into 60% train and 20% val\n",
    "        X_train, X_val, y_train, y_val  = train_test_split(X_full_train, y_full_train, test_size=0.25, random_state=random_state)\n",
    "\n",
    "        X_train = X_train.reset_index(drop=True)\n",
    "        X_val = X_val.reset_index(drop=True)\n",
    "        y_train = y_train.reset_index(drop=True)\n",
    "        y_val = y_val.reset_index(drop=True)\n",
    "        X_test = X_test.reset_index(drop=True)\n",
    "        y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "        # print the shape of all the data splits\n",
    "        print('X_train shape', X_train.shape)\n",
    "        print('X_val shape', X_val.shape)\n",
    "        print('X_test shape', X_test.shape)\n",
    "        print('y_train shape', y_train.shape)\n",
    "        print('y_val shape', y_val.shape)\n",
    "        print('y_test shape', y_test.shape)\n",
    "        \n",
    "        return X_train, X_val, y_train, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features []\n",
      "Numerical features ['ssp']\n",
      "Target feature interaction_type\n"
     ]
    }
   ],
   "source": [
    "# Process the features\n",
    "target_variable = 'interaction_type'\n",
    "\n",
    "# create an instance of the DDITrainData class to process the data\n",
    "train_data = DDITrainData(df, target_variable=target_variable)\n",
    "\n",
    "# get the features and target series\n",
    "cat_features, num_features = train_data.process_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (115084, 1)\n",
      "X_val shape (38362, 1)\n",
      "X_test shape (38362, 1)\n",
      "y_train shape (115084,)\n",
      "y_val shape (38362,)\n",
      "y_test shape (38362,)\n",
      "        ssp\n",
      "0  0.121622\n",
      "1  0.116279\n",
      "2  0.082353\n",
      "3  0.091954\n",
      "4  0.117647\n"
     ]
    }
   ],
   "source": [
    "# split the data in train/val/test sets\n",
    "# use 60%/20%/20% distribution with seed 1\n",
    "# use stratified sampling to ensure the distribution of the target feature is the same in all sets\n",
    "X_train, X_val, y_train, y_val, X_test, y_test = train_data.split_data(test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class DDIModelFactory():\n",
    "    \"\"\"\n",
    "    Factory class for DDI prediction model    \n",
    "    \"\"\"    \n",
    "\n",
    "    def __init__(self, categorical_features, numeric_features):\n",
    "        # Initialize the preprocessing transformers\n",
    "        self.scaler = StandardScaler()        \n",
    "        self.encoder = DictVectorizer(sparse=False)\n",
    "\n",
    "        self.numeric_features = numeric_features\n",
    "        self.categorical_features = categorical_features\n",
    "        \n",
    "        self.models = None\n",
    "        self.model = None\n",
    "\n",
    "    def preprocess_data(self, X, is_training=True):      \n",
    "        \"\"\"\n",
    "        Preprocess the data for training or validation\n",
    "        \"\"\"  \n",
    "        X_dict = X.to_dict(orient='records')\n",
    "        \n",
    "        if is_training:\n",
    "            X_std = self.encoder.fit_transform(X_dict)        \n",
    "        else:\n",
    "            X_std = self.encoder.transform(X_dict)\n",
    "            \n",
    "        print(f'Preprocess X shape {X.shape} training {is_training}')   \n",
    "        # Return the standardized features and target variable\n",
    "        return X_std\n",
    "    \n",
    "    def preprocess_target(self, y):\n",
    "        \"\"\"\n",
    "        Preprocess the target variable to make sure the data starts from 0 and is continuous\n",
    "        The target range starts at 1, so we need to subtract 1 from the target variable\n",
    "        \"\"\"\n",
    "        # encode the target variable\n",
    "        min = y.min()\n",
    "        max = y.max()\n",
    "        y_encoded = y\n",
    "        \n",
    "        if min != 0:\n",
    "            print('Min target value is not 0, encoding  y - 1')\n",
    "            y_encoded = y - 1\n",
    "\n",
    "        return y_encoded\n",
    "        \n",
    "    def train(self, X_train, y_train, random_state=42):\n",
    "        \"\"\"\n",
    "         Train the models\n",
    "        \"\"\"        \n",
    "        if self.models is None:\n",
    "            self.models = {\n",
    "                'logistic_regression': LogisticRegression(C=10, max_iter=1000, random_state=random_state, n_jobs=-1),\n",
    "                'random_forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=random_state, n_jobs=-1),\n",
    "                'xgboost': XGBClassifier(n_estimators=100, max_depth=5, random_state=42, n_jobs=-1),                \n",
    "                'decision_tree': DecisionTreeClassifier(max_depth=5, random_state=random_state)\n",
    "            }\n",
    "        \n",
    "        for model in self.models.keys():\n",
    "            print('Training model', model)\n",
    "            self.models[model].fit(X_train, y_train)            \n",
    "\n",
    "    def evaluate(self, X_val, y_val):\n",
    "        \"\"\"\n",
    "        Evaluate the model on the validation data set and return the metrics\n",
    "        \"\"\"\n",
    "\n",
    "        # create a dataframe to store the metrics\n",
    "        df_metrics = pd.DataFrame(columns=['model', 'accuracy', 'precision', 'recall', 'f1', 'y_pred'])\n",
    "\n",
    "        # define the metrics to be calculated\n",
    "        fn_metrics = { 'accuracy': accuracy_score,'precision': precision_score,'recall': recall_score,'f1': f1_score}\n",
    "\n",
    "        # loop through the models and get its metrics\n",
    "        for model_name in self.models.keys():\n",
    "            \n",
    "            model = self.models[model_name]\n",
    "            y_pred = model.predict(X_val)\n",
    "                        \n",
    "            # add a new row to the dataframe for each model            \n",
    "            df_metrics.loc[len(df_metrics)] = [model_name, 0, 0, 0, 0, y_pred]\n",
    "\n",
    "            # get the row index\n",
    "            row_index = len(df_metrics)-1\n",
    "\n",
    "            # Evaluate the model metrics\n",
    "            for metric in fn_metrics.keys():\n",
    "                score = fn_metrics[metric](y_val, y_val)\n",
    "                df_metrics.at[row_index,metric] = score\n",
    "           \n",
    "        return df_metrics\n",
    "\n",
    "    def save(model_name, path):\n",
    "        \"\"\"\n",
    "        Save the model\n",
    "        \"\"\"\n",
    "        # get the model from the models dictionary\n",
    "        model = self.models[model_name]\n",
    "\n",
    "        if model is None:\n",
    "            print('Model not found')\n",
    "            return\n",
    "            \n",
    "        # save the model\n",
    "        model.save(path)\n",
    "\n",
    "            \n",
    "    def predict(self, X_val):\n",
    "        \"\"\"\n",
    "        Predict the target variable on the validation data set and return the predictions\n",
    "        \"\"\"        \n",
    "        probs = self.model.predict_proba(X_val)\n",
    "        return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess X shape (115084, 1) training True\n",
      "Preprocess X shape (38362, 1) training False\n",
      "Min target value is not 0, encoding  y - 1\n"
     ]
    }
   ],
   "source": [
    "# hot encode the categorical features for the train data\n",
    "model_factory = DDIModelFactory(cat_features, num_features)\n",
    "X_train_std = model_factory.preprocess_data(X_train[cat_features + num_features], True)\n",
    "\n",
    "# hot encode the categorical features for the validation data\n",
    "X_val_std = model_factory.preprocess_data(X_val[cat_features + num_features], False)\n",
    "\n",
    "# preprocess the target variable\n",
    "y_train_encoded = model_factory.preprocess_target(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model logistic_regression\n",
      "Training model random_forest\n",
      "Training model xgboost\n",
      "Training model decision_tree\n"
     ]
    }
   ],
   "source": [
    "# train the models\n",
    "model_factory.train(X_train_std, y_train_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_factory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_metrics\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[52], line 101\u001b[0m, in \u001b[0;36mDDIModelFactory.evaluate\u001b[0;34m(self, X_val, y_val, threshold)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Evaluate the model metrics\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m fn_metrics\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 101\u001b[0m         score \u001b[38;5;241m=\u001b[39m \u001b[43mfn_metrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_binary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m         df_metrics\u001b[38;5;241m.\u001b[39mat[row_index,metric] \u001b[38;5;241m=\u001b[39m score\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_metrics\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1954\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_score\u001b[39m(\n\u001b[1;32m   1826\u001b[0m     y_true,\n\u001b[1;32m   1827\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1833\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1834\u001b[0m ):\n\u001b[1;32m   1835\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   1836\u001b[0m \n\u001b[1;32m   1837\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1952\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   1953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1954\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1955\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1956\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1959\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1573\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1391\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1389\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1390\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1392\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1393\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (y_type, average_options)\n\u001b[1;32m   1394\u001b[0m         )\n\u001b[1;32m   1395\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1396\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1397\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1402\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_val_encoded = model_factory.preprocess_target(y_val)\n",
    "df_metrics = model_factory.evaluate(X_val_std, y_val_encoded)\n",
    "df_metrics.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
