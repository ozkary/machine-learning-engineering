{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Decision Trees and Ensemble Learning\n",
    "\n",
    "## Decision Trees:\n",
    "Decision trees are a versatile tool in machine learning for classification and regression tasks. They mimic human decision-making by creating a flowchart-like structure to make predictions based on input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "The goal of this homework is to create a regression model for predicting housing prices (column 'median_house_value').\n",
    "\n",
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset\n",
    "\n",
    "For this homework, we only want to use a subset of data. This is the same subset we used in homework #2. But in contrast to homework #2 we are going to use all columns of the dataset.\n",
    "\n",
    "First, keep only the records where ocean_proximity is either '<1H OCEAN' or 'INLAND'\n",
    "\n",
    "**Preparation:**\n",
    "\n",
    "- Fill missing values with zeros.\n",
    "- Apply the log tranform to median_house_value.\n",
    "- Do train/validation/test split with 60%/20%/20% distribution.\n",
    "- Use the train_test_split function and set the random_state parameter to 1.\n",
    "- Use DictVectorizer(sparse=True) to turn the dataframes into matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>-121.97</td>\n",
       "      <td>37.64</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>6.0574</td>\n",
       "      <td>431000.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>-121.99</td>\n",
       "      <td>37.61</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3666.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>4.6458</td>\n",
       "      <td>217000.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>-121.97</td>\n",
       "      <td>37.57</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4342.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>2172.0</td>\n",
       "      <td>789.0</td>\n",
       "      <td>4.6146</td>\n",
       "      <td>247600.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-121.96</td>\n",
       "      <td>37.58</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3575.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>5.7192</td>\n",
       "      <td>283500.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>-121.98</td>\n",
       "      <td>37.58</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4126.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>2079.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>3.6832</td>\n",
       "      <td>216900.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "701    -121.97     37.64                32.0       1283.0           194.0   \n",
       "830    -121.99     37.61                 9.0       3666.0           711.0   \n",
       "859    -121.97     37.57                21.0       4342.0           783.0   \n",
       "860    -121.96     37.58                15.0       3575.0           597.0   \n",
       "861    -121.98     37.58                20.0       4126.0          1031.0   \n",
       "\n",
       "     population  households  median_income  median_house_value ocean_proximity  \n",
       "701       485.0       171.0         6.0574            431000.0       <1H OCEAN  \n",
       "830      2341.0       703.0         4.6458            217000.0       <1H OCEAN  \n",
       "859      2172.0       789.0         4.6146            247600.0       <1H OCEAN  \n",
       "860      1777.0       559.0         5.7192            283500.0       <1H OCEAN  \n",
       "861      2079.0       975.0         3.6832            216900.0       <1H OCEAN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data from housing.csv into a Pandas dataframe\n",
    "df = pd.read_csv('housing.csv')\n",
    "\n",
    "# keep only records where ocean_proximity is either '<1H OCEAN' or 'INLAND'\n",
    "df = df[df['ocean_proximity'].isin(['<1H OCEAN', 'INLAND'])]\n",
    "\n",
    "# fill in the missing values with zeros\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply log transform to median_house_value\n",
    "features = 'median_house_value'\n",
    "df[features] = np.log1p(df[features])\n",
    "\n",
    "# split the data in train/val/test sets, with 60%/20%/20% distribution with seed 1\n",
    "# .2 splits the data into 80% train and 20% test\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "#.25 splits the 80% train into 60% train and 20% val\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "# reset the indexes of the dataframes\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# separate the target variable from the train/val/test sets\n",
    "y_train = df_train[features].values\n",
    "y_val = df_val[features].values\n",
    "y_test = df_test[features].values\n",
    "\n",
    "# Separate features and target\n",
    "train_features = df_train.drop(features, axis=1)\n",
    "val_features = df_val.drop(features, axis=1)\n",
    "test_features = df_test.drop(features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (9411, 10)\n",
      "X_val shape: (3138, 10)\n",
      "X_test shape: (3138, 10)\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframes to dictionaries\n",
    "train_dict = train_features.to_dict(orient='records')\n",
    "val_dict = val_features.to_dict(orient='records')\n",
    "test_dict = test_features.to_dict(orient='records')\n",
    "\n",
    "# Initialize DictVectorizer\n",
    "dv = DictVectorizer(sparse=True)\n",
    "\n",
    "# Transform features using DictVectorizer\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "X_val = dv.transform(val_dict)\n",
    "X_test = dv.transform(test_dict)\n",
    "\n",
    "# Print the shapes of transformed data\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_val shape:', X_val.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Let's train a decision tree regressor to predict the median_house_value variable.\n",
    "\n",
    "Train a model with max_depth=1.\n",
    "\n",
    "Which feature is used for splitting the data?\n",
    "\n",
    "- ocean_proximity\n",
    "- total_rooms\n",
    "- latitude\n",
    "- population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature used for splitting: households\n"
     ]
    }
   ],
   "source": [
    "# Train a decision tree regressor with max_depth=1\n",
    "model = DecisionTreeRegressor(max_depth=1, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature used for splitting\n",
    "splitting_feature = train_features.columns[model.tree_.feature[0]]\n",
    "print('The feature used for splitting:', splitting_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46995539 0.46957111 0.46776644 0.46968943 0.47035552] [0.46967075 0.46983277 0.46761814 0.46917852 0.47054857]\n",
      "[0.59992283 0.59930812 0.5964245  0.59949737 0.60056312] [0.59946748 0.59972665 0.59618777 0.59868037 0.60087215]\n",
      "RMSE on validation set: 0.0012937498938391813\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = rf_model.predict(X_val)\n",
    "\n",
    "print (y_val_pred[:5], y_val[:5])\n",
    "\n",
    "y_val_pred_inverse = np.expm1(y_val_pred)  # Inverse log transform\n",
    "y_val_inverse = np.expm1(y_val)  # Inverse log transform\n",
    "\n",
    "print (y_val_pred_inverse[:5], y_val_inverse[:5])\n",
    "\n",
    "rmse = mean_squared_error(y_val, y_val_pred, squared=False)\n",
    "print(f'RMSE on validation set (log): {rmse}')\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = mean_squared_error(y_val_inverse, y_val_pred_inverse, squared=False)\n",
    "print(f'RMSE on validation set (inverse): {rmse}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
