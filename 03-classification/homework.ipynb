{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Classification\n",
    "\n",
    "Classification is a fundamental task in supervised machine learning where the goal is to predict the categorical class or label of a given data point based on its features. In other words, it involves assigning a predefined category to each input instance based on its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data\n",
    "!wget wget https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import accuracy_score, classification_report, mutual_info_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data and Exploratory Data Analysis (EDA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Year</th>\n",
       "      <th>Engine HP</th>\n",
       "      <th>Engine Cylinders</th>\n",
       "      <th>Transmission Type</th>\n",
       "      <th>Vehicle Style</th>\n",
       "      <th>highway MPG</th>\n",
       "      <th>city mpg</th>\n",
       "      <th>MSRP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series M</td>\n",
       "      <td>2011</td>\n",
       "      <td>335.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>46135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>40650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>36350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>29450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>34500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Make       Model  Year  Engine HP  Engine Cylinders Transmission Type  \\\n",
       "0  BMW  1 Series M  2011      335.0               6.0            MANUAL   \n",
       "1  BMW    1 Series  2011      300.0               6.0            MANUAL   \n",
       "2  BMW    1 Series  2011      300.0               6.0            MANUAL   \n",
       "3  BMW    1 Series  2011      230.0               6.0            MANUAL   \n",
       "4  BMW    1 Series  2011      230.0               6.0            MANUAL   \n",
       "\n",
       "  Vehicle Style  highway MPG  city mpg   MSRP  \n",
       "0         Coupe           26        19  46135  \n",
       "1   Convertible           28        19  40650  \n",
       "2         Coupe           28        20  36350  \n",
       "3         Coupe           28        18  29450  \n",
       "4   Convertible           28        18  34500  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    'Make', 'Model','Year','Engine HP','Engine Cylinders','Transmission Type',\n",
    "    'Vehicle Style','highway MPG','city mpg','MSRP'\n",
    "]\n",
    "\n",
    "df = pd.read_csv('data.csv', iterator=False, usecols=features)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>engine_hp</th>\n",
       "      <th>engine_cylinders</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>vehicle_style</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series M</td>\n",
       "      <td>2011</td>\n",
       "      <td>335.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>46135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>40650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>36350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>29450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>34500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  make       model  year  engine_hp  engine_cylinders transmission_type  \\\n",
       "0  BMW  1 Series M  2011      335.0               6.0            MANUAL   \n",
       "1  BMW    1 Series  2011      300.0               6.0            MANUAL   \n",
       "2  BMW    1 Series  2011      300.0               6.0            MANUAL   \n",
       "3  BMW    1 Series  2011      230.0               6.0            MANUAL   \n",
       "4  BMW    1 Series  2011      230.0               6.0            MANUAL   \n",
       "\n",
       "  vehicle_style  highway_mpg  city_mpg  price  \n",
       "0         Coupe           26        19  46135  \n",
       "1   Convertible           28        19  40650  \n",
       "2         Coupe           28        20  36350  \n",
       "3         Coupe           28        18  29450  \n",
       "4   Convertible           28        18  34500  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the column names to lower case and replace spaces with underscores\n",
    "df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
    "\n",
    "# fill the missing values with 0\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# rename msrp to price\n",
    "df.rename(columns={'msrp': 'price'}, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 - What is the most frequent observation (mode) for the column transmission_type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent observation (mode) for transmission_type: AUTOMATIC\n"
     ]
    }
   ],
   "source": [
    "# get the most frequent observation for the transmission type column\n",
    "transmission_mode = df['transmission_type'].mode()[0]\n",
    "\n",
    "print(f'Most frequent observation (mode) for transmission_type: {transmission_mode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_correlation(correlation_matrix):\n",
    "    \"\"\"\n",
    "    Find the maximum correlation between features in a correlation matrix.\n",
    "    Return the names of the two features and the correlation value.\n",
    "    \"\"\"\n",
    "    # Exclude diagonal elements (self-correlation)\n",
    "    np.fill_diagonal(correlation_matrix.values, np.nan)\n",
    "    \n",
    "    # Find the indices of the maximum correlation\n",
    "    max_corr_index = np.nanargmax(correlation_matrix.values)\n",
    "    max_corr_row, max_corr_col = np.unravel_index(max_corr_index, correlation_matrix.shape)\n",
    "    \n",
    "    # Identify the features with the highest correlation\n",
    "    feature1 = correlation_matrix.columns[max_corr_row]\n",
    "    feature2 = correlation_matrix.columns[max_corr_col]\n",
    "    max_corr_value = correlation_matrix.iloc[max_corr_row, max_corr_col]\n",
    "    \n",
    "    return feature1, feature2, max_corr_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 - What are the two features that have the biggest correlation in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['year', 'engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg', 'price']\n",
      "Correlation Matrix: \n",
      "                      year  engine_hp  engine_cylinders  highway_mpg  \\\n",
      "year              1.000000   0.338714         -0.040708     0.258240   \n",
      "engine_hp         0.338714   1.000000          0.774851    -0.415707   \n",
      "engine_cylinders -0.040708   0.774851          1.000000    -0.614541   \n",
      "highway_mpg       0.258240  -0.415707         -0.614541     1.000000   \n",
      "city_mpg          0.198171  -0.424918         -0.587306     0.886829   \n",
      "price             0.227590   0.650095          0.526274    -0.160043   \n",
      "\n",
      "                  city_mpg     price  \n",
      "year              0.198171  0.227590  \n",
      "engine_hp        -0.424918  0.650095  \n",
      "engine_cylinders -0.587306  0.526274  \n",
      "highway_mpg       0.886829 -0.160043  \n",
      "city_mpg          1.000000 -0.157676  \n",
      "price            -0.157676  1.000000  \n",
      "\n",
      "Highest Correlation - Feature 1: highway_mpg Feature 2: city_mpg \n",
      "Highest Correlation Value: 0.89\n"
     ]
    }
   ],
   "source": [
    "# get the numeric features by reading the data types of the columns \n",
    "numeric_features = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "print(f'Numeric features: {numeric_features}')\n",
    "\n",
    "# Create the correlation matrix for the numerical features of your dataset. \n",
    "# In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset\n",
    "corr_matrix = df[numeric_features].corr()\n",
    "print(f'Correlation Matrix: \\n{corr_matrix}\\n')\n",
    "\n",
    "feature1, feature2, max_corr_value = find_max_correlation(corr_matrix)\n",
    "print(f'Highest Correlation - Feature 1: {feature1} Feature 2: {feature2} ')\n",
    "print(f'Highest Correlation Value: {max_corr_value:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make price binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>engine_hp</th>\n",
       "      <th>engine_cylinders</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>vehicle_style</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>price</th>\n",
       "      <th>above_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series M</td>\n",
       "      <td>2011</td>\n",
       "      <td>335.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>46135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>40650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>36350</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>29450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>34500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  make       model  year  engine_hp  engine_cylinders transmission_type  \\\n",
       "0  BMW  1 Series M  2011      335.0               6.0            MANUAL   \n",
       "1  BMW    1 Series  2011      300.0               6.0            MANUAL   \n",
       "2  BMW    1 Series  2011      300.0               6.0            MANUAL   \n",
       "3  BMW    1 Series  2011      230.0               6.0            MANUAL   \n",
       "4  BMW    1 Series  2011      230.0               6.0            MANUAL   \n",
       "\n",
       "  vehicle_style  highway_mpg  city_mpg  price  above_average  \n",
       "0         Coupe           26        19  46135              1  \n",
       "1   Convertible           28        19  40650              1  \n",
       "2         Coupe           28        20  36350              1  \n",
       "3         Coupe           28        18  29450              0  \n",
       "4   Convertible           28        18  34500              1  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the price column binary getting the price median value and then adding a new column above_average = 1 when price > median and 0 otherwise\n",
    "price_median = df['price'].median()\n",
    "df['above_average'] = (df['price'] > price_median).astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data\n",
    "- Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "- Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.\n",
    "- Make sure that the target value (price) is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data length:  7148 price values length:  7148\n"
     ]
    }
   ],
   "source": [
    "# split the data in train/val/test sets, with 60%/20%/20% distribution with seed 42\n",
    "# .2 splits the data into 80% train and 20% test\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "#.25 splits the 80% train into 60% train and 20% val\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# reset the indexes of the dataframes\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# separate the target variable from the train/val/test sets\n",
    "y_train = df_train.price.values\n",
    "y_val = df_val.price.values\n",
    "y_test = df_test.price.values\n",
    "\n",
    "# delete the price column from the train/val/test sets\n",
    "del df_train['price']\n",
    "del df_val['price']\n",
    "del df_test['price']\n",
    "\n",
    "print('train data length: ',len(df_train),'price values length: ', len(y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 - Which of these variables has the lowest mutual information score?\n",
    "\n",
    "- Calculate the mutual information score between above_average and other categorical variables in our dataset. Use the training set only.\n",
    "- Round the scores to 2 decimals using round(score, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Score: \n",
      "make                 0.191186\n",
      "model                0.536538\n",
      "transmission_type    0.054405\n",
      "vehicle_style        0.091207\n",
      "dtype: float64\n",
      "\n",
      "Lowest Mutual Information Score: transmission_type 0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using the training set only, calculate the mutual information score between above_average and other categorical variables\n",
    "# use the training set only\n",
    "categorical_features = ['make', 'model', 'transmission_type', 'vehicle_style']\n",
    "df_train_categorical = df_train[categorical_features]\n",
    "\n",
    "# calculate the mutual information score between above_average and other categorical variables\n",
    "def mutual_info_price_score(series):\n",
    "    return mutual_info_score(series, df_train['above_average'])\n",
    "\n",
    "mi = df_train_categorical.apply(mutual_info_price_score)\n",
    "mi.sort_values(ascending=False).round(2)\n",
    "\n",
    "# A higher MI score indicates a stronger relationship between a categorical feature and the target variable, \n",
    "# making it potentially more informative for predicting the target.\n",
    "print(f'Mutual Information Score: \\n{mi}\\n')\n",
    "\n",
    "# print the lowest MI score and the feature name\n",
    "lowest_mi_score = mi.idxmin()\n",
    "print(f'Lowest Mutual Information Score: {lowest_mi_score} {mi[lowest_mi_score]:.2f}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 - Calculate the accuracy on the validation dataset\n",
    "\n",
    "Now let's train a logistic regression.\n",
    "- Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "  - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "  - model = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "- Calculate the accuracy on the validation dataset and round it to 2 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy (df_train, df_val, features, y_train, y_val) -> float:\n",
    "\n",
    "    # Convert each category into a binary vector (a series of 0s and 1s). \n",
    "    # Each category becomes a new column with a 1 or 0 indicating the presence of that category.\n",
    "    encoder = OneHotEncoder(sparse_output=False,  handle_unknown='ignore')  \n",
    "        \n",
    "    # one-hot encode the categorical variables    \n",
    "    X_train = encoder.fit_transform(df_train[features].values, True)    \n",
    "\n",
    "    # train a logistic regression model use (solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "    model = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, df_train['above_average'].values)\n",
    "          \n",
    "    # process the validation set in the same way you processed the training set     \n",
    "    X_val = encoder.transform(df_val[features].values)\n",
    "        \n",
    "    # calculate the accuracy on the validation dataset and round it to 2 decimal digits\n",
    "    y_pred = model.predict(X_val)\n",
    "    # y_pred = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Calculate accuracy on validation set\n",
    "    accuracy = accuracy_score(df_val['above_average'].values,  y_pred)\n",
    "    rounded_accuracy = round(accuracy,6 )\n",
    "    print(f'Accuracy: {rounded_accuracy} with features: {features}')\n",
    "\n",
    "    return rounded_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a logistic regression model with the one-hot encoded categorical variables\n",
    "# use the training set only\n",
    "# use the same encoder instance to avoid data leakage\n",
    "def calculate_feature_accuracy (df_train, df_val, cat_features, num_features, y_train, y_val) -> float:\n",
    "\n",
    "    # Convert each category into a binary vector (a series of 0s and 1s). \n",
    "    # Each category becomes a new column with a 1 or 0 indicating the presence of that category.\n",
    "    encoder = OneHotEncoder(sparse_output=False,  handle_unknown='ignore')  \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # scale and encode the train and validation sets    \n",
    "    X_train_num = scaler.fit_transform(df_train[num_features].values)         \n",
    "    X_val_num = scaler.transform(df_val[num_features].values) \n",
    "\n",
    "    # one-hot encode the categorical variables    \n",
    "    X_train_cat_encoded = encoder.fit_transform(df_train[cat_features].values, True)\n",
    "    X_train = np.column_stack([X_train_num, X_train_cat_encoded])\n",
    "\n",
    "    # train a logistic regression model use (solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "    model = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # process the validation set in the same way you processed the training set     \n",
    "    X_val_cat_encoded = encoder.transform(df_val[cat_features].values)\n",
    "    X_val = np.column_stack([X_val_num, X_val_cat_encoded])\n",
    "        \n",
    "    # calculate the accuracy on the validation dataset and round it to 2 decimal digits\n",
    "    y_pred = model.predict(X_val)\n",
    "    # y_pred = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Calculate accuracy on validation set\n",
    "    accuracy = accuracy_score(y_val,  y_pred)\n",
    "    rounded_accuracy = round(accuracy,3 )\n",
    "    print(f'Accuracy: {rounded_accuracy} with features: {num_features} {cat_features}')\n",
    "\n",
    "    return rounded_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.937054 with features: ['make', 'model', 'year', 'engine_hp', 'engine_cylinders', 'transmission_type', 'vehicle_style', 'highway_mpg', 'city_mpg']\n"
     ]
    }
   ],
   "source": [
    "# feature name provides all the features except the target variable\n",
    "feature_names = df_train.columns.tolist()\n",
    "feature_names.remove('above_average')\n",
    "\n",
    "numeric_features_names = numeric_features.copy()\n",
    "numeric_features_names.remove('price')  \n",
    "y_train_target = df_train['above_average'].values\n",
    "y_val_target = df_val['above_average'].values\n",
    "\n",
    "# accuracy_all_features = calculate_feature_accuracy(df_train, df_val, feature_names, numeric_features_names, y_train_target, y_val_target)\n",
    "accuracy_all_features = calc_accuracy(df_train, df_val, feature_names, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 - Which of following feature has the smallest difference?\n",
    "\n",
    "Let's find the least useful feature using the feature elimination technique.\n",
    "- Train a model with all these features (using the same parameters as in Q4).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.933277 with features: ['model', 'year', 'engine_hp', 'engine_cylinders', 'transmission_type', 'vehicle_style', 'highway_mpg', 'city_mpg']\n",
      "Accuracy: 0.929081 with features: ['make', 'year', 'engine_hp', 'engine_cylinders', 'transmission_type', 'vehicle_style', 'highway_mpg', 'city_mpg']\n",
      "Accuracy: 0.929081 with features: ['make', 'model', 'engine_hp', 'engine_cylinders', 'transmission_type', 'vehicle_style', 'highway_mpg', 'city_mpg']\n",
      "Accuracy: 0.929081 with features: ['make', 'model', 'year', 'engine_cylinders', 'transmission_type', 'vehicle_style', 'highway_mpg', 'city_mpg']\n",
      "Accuracy: 0.934536 with features: ['make', 'model', 'year', 'engine_hp', 'transmission_type', 'vehicle_style', 'highway_mpg', 'city_mpg']\n",
      "Accuracy: 0.934956 with features: ['make', 'model', 'year', 'engine_hp', 'engine_cylinders', 'vehicle_style', 'highway_mpg', 'city_mpg']\n",
      "Accuracy: 0.933277 with features: ['make', 'model', 'year', 'engine_hp', 'engine_cylinders', 'transmission_type', 'highway_mpg', 'city_mpg']\n",
      "Accuracy: 0.931179 with features: ['make', 'model', 'year', 'engine_hp', 'engine_cylinders', 'transmission_type', 'vehicle_style', 'city_mpg']\n",
      "Accuracy: 0.936634 with features: ['make', 'model', 'year', 'engine_hp', 'engine_cylinders', 'transmission_type', 'vehicle_style', 'highway_mpg']\n",
      "Feature with smallest difference: city_mpg 0.00042000000000008697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# track the accuracy everytime you remove a feature from the dataset\n",
    "track_accuracy = {}\n",
    "\n",
    "# foreach feature in the categorical_features list, train a model without that feature and calculate the accuracy on the validation dataset\n",
    "for feature in feature_names:\n",
    "\n",
    "    all_features = feature_names.copy()\n",
    "    all_features.remove(feature)\n",
    "\n",
    "    # accuracy_without_feature = calculate_feature_accuracy(df_train, df_val, cat_features, num_features, y_train_target, y_val_target)\n",
    "    accuracy_without_feature = calc_accuracy(df_train, df_val, all_features, y_train, y_val)\n",
    "    \n",
    "    # calculate the difference between accuracy_all_features and accuracy_without_feature    \n",
    "    accuracy_difference = accuracy_all_features - accuracy_without_feature\n",
    "    track_accuracy[feature] = accuracy_difference\n",
    "\n",
    "# select the smallest difference \n",
    "feature_with_smallest_difference = min(track_accuracy, key=track_accuracy.get)\n",
    "print(f'Feature with smallest difference: {feature_with_smallest_difference} {track_accuracy[feature_with_smallest_difference]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling by processing the numerical columns and the categorical columns separately\n",
    "def scale_num_features(df, features, scaler, fit_model= True) -> np.ndarray:\n",
    "\n",
    "    \"\"\"\n",
    "    Scale the numerical columns using StandardScaler\n",
    "    \"\"\"\n",
    "    \n",
    "    # scale the numerical columns\n",
    "    # scaler = StandardScaler()\n",
    "    df_numerical = df[features]\n",
    "    X_train_num = None\n",
    "\n",
    "    if fit_model:\n",
    "        X_train_num = scaler.fit_transform(df_numerical.values) \n",
    "    else:\n",
    "        X_train_num = scaler.transform(df_numerical.values) \n",
    "    \n",
    "    scaler.fit_transform(df_numerical.values)\n",
    "\n",
    "    return X_train_num\n",
    "    \n",
    "def scale_cat_features(df, features, encoder, fit_model= True) -> np.ndarray:\n",
    "\n",
    "    \"\"\"\n",
    "    Scale the categorical columns using OneHotEncoder \n",
    "    \"\"\"\n",
    "    \n",
    "    # one-hot encode the categorical variables\n",
    "    # encoder = OneHotEncoder(sparse_output=False,  handle_unknown='ignore')  \n",
    "    df_categorical = df[features]\n",
    "    X_train_cat = None\n",
    "    \n",
    "    if fit_model:\n",
    "        X_train_cat = encoder.fit_transform(df_categorical.values)\n",
    "    else:\n",
    "        X_train_cat = encoder.transform(df_categorical.values)\n",
    "    \n",
    "    return X_train_cat\n",
    "\n",
    "def scale_encode_features(df, num_features, cat_features, scaler, encoder, fit_model= True) -> np.ndarray:\n",
    "\n",
    "    \"\"\"\n",
    "    Scale the numerical and categorical columns\n",
    "    \"\"\"\n",
    "    \n",
    "    # scale the numerical columns\n",
    "    X_train_num = scale_num_features(df, num_features, scaler, fit_model)\n",
    "        \n",
    "    # one-hot encode the categorical variables    \n",
    "    X_train_cat = scale_cat_features(df, cat_features,encoder, fit_model)\n",
    "    \n",
    "    # concatenate the numerical and categorical columns\n",
    "    X_train = np.column_stack([X_train_num, X_train_cat])\n",
    "    \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 - Which of these alphas leads to the best RMSE on the validation set?\n",
    "\n",
    "For this question, we'll see how to use a linear regression model from Scikit-Learn.\n",
    "- We need to use the original column price. Apply the logarithmic transformation to this column.\n",
    "- Fit the Ridge regression model on the training data with a solver 'sag'. Set the seed to 42.\n",
    "- This model also has a parameter alpha. Let's try the following values: [0, 0.01, 0.1, 1, 10].\n",
    "- Round your RMSE scores to 3 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSRP: 10.13\n",
      "\n",
      "RMSE for alpha=0: 81134.1537097014\n",
      "Example y_pred for alpha=0: [24730.91610139 48620.65328883 21802.31510211 41870.97448071\n",
      "  1953.20717633]\n",
      "RMSE Scores: \n",
      "[(0, 81134.1537097014)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply the logarithmic transformation to the price variable which has original price (y_train)\n",
    "y_log_train = np.log1p(y_train)\n",
    "average_msrp = y_log_train.mean()\n",
    "print(f'Average MSRP: {average_msrp:.2f}\\n')\n",
    "\n",
    "# List of alpha values to try\n",
    "alpha_values = [0]\n",
    "# , 0.01, 0.1, 1, 10]\n",
    "\n",
    "# Train Ridge regression models with different alpha values\n",
    "# A higher alpha leads to stronger regularization, which can help prevent overfitting but may make the model too biased.\n",
    "rmse_scores = []\n",
    "\n",
    "# instantiate the scaler and encoder\n",
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder(sparse_output=False,  handle_unknown='ignore')\n",
    "\n",
    "# standardize the numeric and categorical features for the train set\n",
    "X_train_std = scale_encode_features(df_train, numeric_features_names, categorical_features, scaler, encoder, True)\n",
    "\n",
    "# standardize the numeric and categorical features for the validation set\n",
    "y_val_std = scale_encode_features(df_val, numeric_features_names, categorical_features, scaler, encoder, False)\n",
    "\n",
    "# define the ridge model    \n",
    "ridge_model = Ridge(alpha=alpha, solver='sag', random_state=42, max_iter=5000)\n",
    "for alpha in alpha_values:\n",
    "            \n",
    "    # fit the training data to the model    \n",
    "    ridge_model.fit(X_train_std, y_log_train)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    # y_log_val = np.log1p(y_val_std)\n",
    "\n",
    "    # show nan values\n",
    "    # print(np.isnan(y_log_val).any())\n",
    "    y_log_pred = ridge_model.predict(y_val_std)\n",
    "\n",
    "    # convert prediction back to original scale\n",
    "    y_pred = np.expm1(y_log_pred)\n",
    "    print(f\"Example y_pred for alpha={alpha}: {y_log_pred[:5]}\")  # Display first 5 predictions\n",
    "    \n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "    print(f\"RMSE for alpha={alpha}: {rmse}\")\n",
    "    print(f\"Example y_pred for alpha={alpha}: {y_pred[:5]}\")  # Display first 5 predictions\n",
    "\n",
    "    y_log_test = np.log1p(y_test)\n",
    "    rmse = mean_squared_error(y_log_test, y_log_pred, squared=False)\n",
    "    print(f\"RMSE for alpha={alpha}: {rmse}\")\n",
    "    \n",
    "\n",
    "    # Append the RMSE to the list\n",
    "    rmse_scores.append((alpha, rmse))\n",
    "\n",
    "print(f'RMSE Scores: \\n{rmse_scores}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
