{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Install Pipenv\n",
    "\n",
    "What's the version of pipenv you installed?\n",
    "Use --version to find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mpipenv\u001b[0m, version 2023.10.3\n"
     ]
    }
   ],
   "source": [
    "!pipenv --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Use Pipenv to install Scikit-Learn version 1.3.1\n",
    "\n",
    "What's the first hash for scikit-learn you get in Pipfile.lock?\n",
    "\n",
    "- sha256:0c275a06c5190c5ce00af0acbb61c06374087949f643ef32d355ece12c4db043"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dictionary vectrorizer and a logistic regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/model1.bin: Scheme missing.\n",
      "/dv.bin: Scheme missing.\n"
     ]
    }
   ],
   "source": [
    "!PREFIX=https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2023/05-deployment/homework\n",
    "!wget $PREFIX/model1.bin\n",
    "!wget $PREFIX/dv.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Let's use these models!\n",
    "\n",
    "- Write a script for loading these models with pickle\n",
    "- Score this client:\n",
    "\n",
    "```\n",
    "{\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit?\n",
    "\n",
    "- 0.162\n",
    "- 0.392\n",
    "- 0.652\n",
    "- 0.902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1:\n",
      "Class no: Probability 0.098\n",
      "Class yes: Probability 0.902\n",
      "Probability the client would get a credit: yes - 0.902   no - 0.098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ozkary/.local/lib/python3.8/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DictVectorizer from version 1.3.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/ozkary/.local/lib/python3.8/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.3.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the DictVectorizer\n",
    "with open('dv.bin', 'rb') as f:\n",
    "    dv = pickle.load(f)\n",
    "\n",
    "# Load the Logistic Regression model\n",
    "with open('model1.bin', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# New data for prediction\n",
    "new_data = {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "\n",
    "# Transform the new data using the DictVectorizer\n",
    "transformed_data = dv.transform([new_data])\n",
    "\n",
    "# Predict using the loaded model\n",
    "probabilities = model.predict_proba(transformed_data)\n",
    "\n",
    "# break down the probabilities into yes or no score\n",
    "no_score, yes_score = probabilities[0]\n",
    "\n",
    "# get the class labels from the model\n",
    "no_label, yes_label = model.classes_\n",
    "\n",
    "for i, probs in enumerate(probabilities):\n",
    "    print(f\"Prediction {i+1}:\")\n",
    "    for label, prob in zip(model.classes_, probs):\n",
    "        print(f\"Class {label}: Probability {prob:.3f}\")\n",
    "\n",
    "# Print the probability scores for each class\n",
    "print(f'Probability the client would get a credit: {yes_label} - {yes_score:.3f}   {no_label} - {no_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 - Now let's serve this model as a web service\n",
    "\n",
    "- Install Flask and gunicorn (or waitress, if you're on Windows)\n",
    "- Write Flask code for serving the model\n",
    "- Now score this client using requests:\n",
    "\n",
    "```python \n",
    "url = \"YOUR_URL\"\n",
    "client = {\"job\": \"unknown\", \"duration\": 270, \"poutcome\": \"failure\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "What's the probability that this client will get a credit?\n",
    "\n",
    "- 0.140\n",
    "- 0.440\n",
    "- 0.645\n",
    "- 0.845"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipenv shell\n",
    "\n",
    "- Activate the pipenv shell in the working directory\n",
    "\n",
    "```bash\n",
    "cd your_project_directory\n",
    "pipenv shell\n",
    "\n",
    "```\n",
    "\n",
    "- Install Flask and Gunicorn\n",
    "\n",
    "```bash\n",
    "pipenv install flask gunicorn\n",
    "```\n",
    "\n",
    "- Make the API request to make the prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API Code\n",
    "\n",
    "```python\n",
    "# app.py - Your Flask application\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the DictVectorizer\n",
    "with open('dv.bin', 'rb') as f:\n",
    "    dv = pickle.load(f)\n",
    "\n",
    "file_path = 'model1.bin' if os.path.exists('model1.bin') else 'model2.bin' \n",
    "\n",
    "# Load the Logistic Regression model\n",
    "with open(file_path, 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Define the prediction endpoint and route\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # get the json payload\n",
    "    data = request.get_json()\n",
    "    print(\"data\",data)\n",
    "    \n",
    "    # Transform the new data using the DictVectorizer\n",
    "    transformed_data = dv.transform([data])\n",
    "\n",
    "    # Process the data, make predictions using the model, and return the results\n",
    "    probabilities = model.predict_proba(transformed_data)\n",
    "\n",
    "    # break down the probabilities into yes or no score\n",
    "    no_score, yes_score = probabilities[0]\n",
    "\n",
    "    # get the class labels from the model\n",
    "    no_label, yes_label = model.classes_    \n",
    "    return jsonify({'yes': yes_score, 'no': no_score})\n",
    "    \n",
    "# load the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Response: {'no': 0.8603105294764318, 'yes': 0.13968947052356817}\n"
     ]
    }
   ],
   "source": [
    "# Make the request to make the prediction\n",
    "import requests\n",
    "\n",
    "url = 'http://0.0.0.0:8000/predict'\n",
    "client = {\"job\": \"unknown\", \"duration\": 270, \"poutcome\": \"failure\"}\n",
    "response = requests.post(url, json=client)\n",
    "\n",
    "# Check the response status code\n",
    "if response.status_code == 200:\n",
    "    # If the response status is 200 (OK), print the JSON response\n",
    "    json_response = response.json()\n",
    "    print(f\"JSON Response: {json_response}\")    \n",
    "else:\n",
    "    # If the response status is not 200, print an error message\n",
    "    print(\"Error:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 - Docker Image\n",
    "\n",
    "- Download the base image svizor/zoomcamp-model:3.10.12-slim. You can easily make it by using docker pull command.\n",
    "\n",
    "So what's the size of this base image?\n",
    "\n",
    "47 MB\n",
    "147 MB\n",
    "374 MB\n",
    "574 MB\n",
    "\n",
    "You can get this information when running docker images - it'll be in the \"SIZE\" column.\n",
    "\n",
    "```\n",
    "svizor/zoomcamp-model       3.10.12-slim   08266c8f0c4b   4 days ago      147MB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dockerfile\n",
    "\n",
    "Now create your own Dockerfile based on the image we prepared.\n",
    "\n",
    "It should start like that:\n",
    "\n",
    "```python\n",
    "FROM svizor/zoomcamp-model:3.10.12-slim\n",
    "# add your stuff here\n",
    "```\n",
    "\n",
    "Now complete it:\n",
    "\n",
    "- Install all the dependencies form the Pipenv file\n",
    "- Copy your Flask script\n",
    "- Run it with Gunicorn\n",
    "\n",
    "After that, you can build your docker image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 Add the solution on a Docker Container\n",
    "Let's run your docker container!\n",
    "\n",
    "After running it, score this client once again:\n",
    "\n",
    "```python \n",
    "\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "What's the probability that this client will get a credit now?\n",
    "\n",
    "- 0.168\n",
    "- 0.530\n",
    "- 0.730\n",
    "- 0.968"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker file code\n",
    "\n",
    "```bash\n",
    "# Use the base image\n",
    "FROM svizor/zoomcamp-model:3.10.12-slim\n",
    "\n",
    "# Set the working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy the Pipenv files to the container\n",
    "COPY Pipfile Pipfile.lock /app/\n",
    "\n",
    "# Install pipenv and dependencies\n",
    "RUN pip install pipenv\n",
    "RUN pipenv install --system --deploy\n",
    "\n",
    "# Copy the Flask script to the container\n",
    "COPY app.py /app/\n",
    "\n",
    "# Expose the port your Flask app runs on\n",
    "EXPOSE 8000\n",
    "\n",
    "# Run the Flask app with Gunicorn\n",
    "CMD [\"gunicorn\", \"app:app\", \"--bind\", \"0.0.0.0:8000\", \"--workers\", \"4\"]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Response: {'no': 0.27306305364457695, 'yes': 0.726936946355423}\n"
     ]
    }
   ],
   "source": [
    "# run the API from a docker container\n",
    "\n",
    "client =  {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "response = requests.post(url, json=client)\n",
    "\n",
    "# Check the response status code\n",
    "if response.status_code == 200:\n",
    "    # If the response status is 200 (OK), print the JSON response\n",
    "    json_response = response.json()\n",
    "    print(f\"JSON Response: {json_response}\")    \n",
    "else:\n",
    "    # If the response status is not 200, print an error message\n",
    "    print(\"Error:\", response.status_code)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
